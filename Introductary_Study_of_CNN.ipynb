{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Introductary_Study_of_CNN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "Thv5T4Ie651P",
        "colab_type": "code",
        "outputId": "787812a7-f00a-40ef-b9c1-72dd981d093d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "# TensorFlow and tf.keras\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.utils import to_categorical\n",
        "from keras import layers\n",
        "from keras import models\n",
        "\n",
        "# Helper libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.12.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "4mr437xhxJik",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "For this week's study, I will start from the simple construction of CNN in tensorflow. It would be necessary to use the mature APIs from Keras. The datasets using here are classic examples using to test the neural networks, which are the Fashion MNIST dataset and the Hand-writing MNIST dataset. I would reload these two datasets first."
      ]
    },
    {
      "metadata": {
        "id": "Pa3TqFl6yHzv",
        "colab_type": "code",
        "outputId": "85b2db75-b29a-4344-f1d0-0ce10ff19378",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "cell_type": "code",
      "source": [
        "fashion_mnist = keras.datasets.fashion_mnist # Initialize the fashion_mnist data object\n",
        "(train_img, train_label), (test_img, test_label) = fashion_mnist.load_data()\n",
        "\n",
        "mnist = keras.datasets.mnist # Initialize the mnist hand-writing data\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "print(x_train.size)\n",
        "print(y_train.size)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "47040000\n",
            "60000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Y_EfchZs0NYs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Simple Example of CNN structure implementation**\n",
        "\n",
        "We could use the MNIST data for a simple example of a CNN structure from 1 layer to 3 layers by Keras. Before the training, one important thing is to do the data preparation. We need to transfer the data into the form for training."
      ]
    },
    {
      "metadata": {
        "id": "1E4OAjSH0NnM",
        "colab_type": "code",
        "outputId": "48d29437-6895-4d00-8e24-1f1f1e4ee311",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        }
      },
      "cell_type": "code",
      "source": [
        "# Data preparation of MNIST Handwriting images\n",
        "x_train = x_train.reshape((60000,28,28,1)) # 60000 training images. Each image has 28 by 28 pixels with 1 colour channel\n",
        "x_train = x_train.astype('float32')/255 # Normalize each pixel's value\n",
        "x_test = x_test.reshape((10000,28,28,1)) # 10000 testing images.\n",
        "x_test = x_test.astype('float32')/255\n",
        "\n",
        "y_train = to_categorical(y_train) # Converts the label class vector (integers) to binary class matrix.\n",
        "y_test = to_categorical(y_test)\n",
        "\n",
        "\n",
        "fig = plt.figure(figsize = (10,50))\n",
        "ax = fig.add_subplot(1,5,1)\n",
        "plt.imshow(x_train[0].reshape((28,28)))\n",
        "ax = fig.add_subplot(1,5,2)\n",
        "plt.imshow(x_train[1].reshape((28,28)))\n",
        "ax = fig.add_subplot(1,5,3)\n",
        "plt.imshow(x_train[2].reshape((28,28)))\n",
        "ax = fig.add_subplot(1,5,4)\n",
        "plt.imshow(x_train[3].reshape((28,28)))\n",
        "ax = fig.add_subplot(1,5,5)\n",
        "plt.imshow(x_train[4].reshape((28,28)))\n",
        "plt.show()\n",
        "print(y_train[0:4])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAk4AAACBCAYAAAA2eDW9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJnaciIiIiDT9H5OQrtW976VAAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 720x3600 with 5 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Hadu6f8kXE10",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We would build an example of one simple layer Convolutional Neural Network. In keras, we can use the 'model' and 'layers' packs to do the construction. Usually one layer of Convolutional Neural Network would have a layer of Convolution operation (Distinguish the convolution operation for 1-dimensional data or 2-dimensional data), a layer of activation (usually we can use a RELU activation layer), a layer of Pooling (usaully we could the MaxPooling).\n",
        "\n",
        "After the structure of CNN, we want to accomplish our goal. Here the goal is to do the classification, then after the one layer CNN, we would want to flatten the output layer (out put of the CNN structure) first and use the fully-connected activation layer (RELU). Then we will use a final fully-connected sigmoid/softmax layer to have our results for classification. We could code it step by step. "
      ]
    },
    {
      "metadata": {
        "id": "QBuahPuPSEfv",
        "colab_type": "code",
        "outputId": "30f81011-9f92-43cb-e121-3d75c39e4952",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        }
      },
      "cell_type": "code",
      "source": [
        "# One simple layer of CNN\n",
        "CNN_one_layer = models.Sequential() # Define sequential model so that we could keep adding different layers\n",
        "CNN_one_layer.add(layers.Conv2D(filters=16,kernel_size=(4,4),padding='valid',activation='relu',input_shape=(28,28,1)))\n",
        "# Here the attribute 'padding' is actually asking the boundary would be counted in or not. 'valid' means not counted in.\n",
        "CNN_one_layer.add(layers.MaxPooling2D((4,4))) # Add the Pooling layer\n",
        "\n",
        "print(CNN_one_layer.summary()) # Track the Output dimension and the number of the parameters\n",
        "\n",
        "CNN_one_layer.add(layers.Flatten())\n",
        "CNN_one_layer.add(layers.Dense(16,activation='relu'))\n",
        "CNN_one_layer.add(layers.Dense(10,activation='softmax')) # Remember the final output's size is 10 because we have only 10 classes\n",
        "\n",
        "print(CNN_one_layer.summary())\n",
        "\n",
        "CNN_one_layer.compile(optimizer='rmsprop', loss='categorical_crossentropy',metrics=['accuracy']) # Model compile\n",
        "CNN_one_layer.fit(x_train,y_train,epochs=1, batch_size=16) # Start the training Process\n",
        "_,test_accuracy = CNN_one_layer.evaluate(x_test,y_test) # Calculate the test accuracy\n",
        "print(test_accuracy)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 25, 25, 16)        272       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 6, 6, 16)          0         \n",
            "=================================================================\n",
            "Total params: 272\n",
            "Trainable params: 272\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 25, 25, 16)        272       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 6, 6, 16)          0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 576)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 16)                9232      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                170       \n",
            "=================================================================\n",
            "Total params: 9,674\n",
            "Trainable params: 9,674\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/1\n",
            "60000/60000 [==============================] - 32s 528us/step - loss: 0.2719 - acc: 0.9196\n",
            "10000/10000 [==============================] - 2s 240us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9683"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "id": "7kVGP4O6eOA6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "After we have the basic idea of the construction, we could just build more layers. To make the training process more complete, it would be better to include the K-Fold cross validation (Though MNIST data just a very simple dataset). We can import KFOLD from sk-learn and combine it into the training process by a simple for loop."
      ]
    },
    {
      "metadata": {
        "id": "hJP2UI95eW3R",
        "colab_type": "code",
        "outputId": "6f231c8f-7d29-47a6-cd59-e556f22d2823",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        }
      },
      "cell_type": "code",
      "source": [
        "model_mnist = models.Sequential()\n",
        "model_mnist.add(layers.Conv2D(16,(4,4),activation='relu',input_shape=(28,28,1)))\n",
        "model_mnist.add(layers.MaxPooling2D(2,2))\n",
        "model_mnist.add(layers.Conv2D(32,(3,3),activation='relu'))\n",
        "model_mnist.add(layers.MaxPooling2D(2,2))\n",
        "model_mnist.add(layers.Conv2D(32,(2,2),activation='relu'))\n",
        "\n",
        "model_mnist.add(layers.Flatten())\n",
        "model_mnist.add(layers.Dense(32,activation='relu'))\n",
        "model_mnist.add(layers.Dense(10,activation='softmax'))\n",
        "\n",
        "print(model_mnist.summary())\n",
        "\n",
        "model_mnist.compile(optimizer='rmsprop', loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "model_mnist.fit(x_train,y_train,epochs=5, batch_size=16)\n",
        "_,test_accuracy = model_mnist.evaluate(x_test,y_test)\n",
        "print(test_accuracy)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_85 (Conv2D)           (None, 25, 25, 16)        272       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_58 (MaxPooling (None, 12, 12, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_86 (Conv2D)           (None, 10, 10, 32)        4640      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_59 (MaxPooling (None, 5, 5, 32)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_87 (Conv2D)           (None, 4, 4, 32)          4128      \n",
            "_________________________________________________________________\n",
            "flatten_25 (Flatten)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_49 (Dense)             (None, 32)                16416     \n",
            "_________________________________________________________________\n",
            "dense_50 (Dense)             (None, 10)                330       \n",
            "=================================================================\n",
            "Total params: 25,786\n",
            "Trainable params: 25,786\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 47s 789us/step - loss: 0.1561 - acc: 0.9518\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 47s 782us/step - loss: 0.0540 - acc: 0.9838\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 46s 763us/step - loss: 0.0436 - acc: 0.9874\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 46s 771us/step - loss: 0.0385 - acc: 0.9894\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 47s 776us/step - loss: 0.0345 - acc: 0.9906\n",
            "10000/10000 [==============================] - 3s 311us/step\n",
            "0.9898\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hdNIxibHpe7Z",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The basic neural networks just have a very simple idea that you could think you build a layer of logistic regression among a layer of logistic regression. A densily connected network would be much easir to construct and train. However, to sequential data, especially the 2-D sequential data (images), CNN would normally have a better result. The convolution operations help a lot. The fully connected networks would try to learn global patterns among the whole input feature space. But with the convolution operations, local patterns will be discovered and exaggrated. For instance, detect the patterns on some edges might give a more efficient classification result.\n",
        "\n",
        "We would want to do a little visualization of our CNN training process to have a better idea about the convolution operations."
      ]
    },
    {
      "metadata": {
        "id": "lN_J9z-trM53",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8SIQY9pwn4Oz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    }
  ]
}